\section{Direct MLE Method}
Directly solve the MLE problem by computing gradients of $\ell(\theta, \sigma)$ w.r.t $\theta$ and $\sigma$. This is, in general, intractable for arbitrary nonlinear ICA models but worst-case thinking does not apply to our special cases.

\subsubsection*{Gradient w.r.t $\theta$}
$$
\begin{aligned}
\nabla_{\theta} \ell(\theta, \sigma) &= \sum_{i=1}^{k} \int \nabla_{\theta} \varphi\left(x^{(i)} ; g_{\theta}(z), \sigma^{2} I\right) \varphi(z ; 0, I) dz \\
&= \sum_{i=1}^{k} \int \left(2\pi\sigma^{2}\right)^{-n/2} \nabla_{\theta} \exp \left(-\frac{{\lVert x^{(i)} - g_{\theta}(z) \rVert}_{2}^{2}}{2\sigma^{2}}\right) \varphi(z ; 0, I) dz \\
&= \sum_{i=1}^{k} \int \nabla_{\theta} \left(-\frac{{\lVert x^{(i)} - g_{\theta}(z) \rVert}_{2}^{2}}{2\sigma^{2}}\right) \varphi\left(x^{(i)} ; g_{\theta}(z), \sigma^{2} I\right) \varphi(z ; 0, I) dz \\
&= \sum_{i=1}^{k} \int \left[\frac{1}{\sigma^{2}} \cdot{\left(x^{(i)} - g_{\theta}(z)\right)^{T} \nabla_{\theta} g_{\theta}(z)}\right] \varphi\left(x^{(i)} ; g_{\theta}(z), \sigma^{2} I\right) \varphi(z ; 0, I) dz \\
\end{aligned}
$$

\subsubsection*{Gradient w.r.t $\sigma^{2}$}
$$
\begin{aligned}
\nabla_{\sigma^{2}} \ell(\theta, \sigma) &= \sum_{i=1}^{k} \int \nabla_{\sigma^{2}} \varphi\left(x^{(i)} ; g_{\theta}(z), \sigma^{2} I\right) \varphi(z ; 0, I) dz \\
&= \sum_{i=1}^{k} \int \nabla_{\sigma^{2}} \left(2\pi\sigma^{2}\right)^{-n/2} \exp \left(-\frac{{\lVert x^{(i)} - g_{\theta}(z) \rVert}_{2}^{2}}{2\sigma^{2}}\right) \varphi(z ; 0, I) dz \\
&= \sum_{i=1}^{k} \int \left[\frac{1}{2\sigma^{2}} \cdot \left(-n + \frac{{\lVert x^{(i)} - g_{\theta}(z) \rVert}_{2}^{2}} {\sigma^{2}}\right)\right] \varphi\left(x^{(i)} ; g_{\theta}(z), \sigma^{2} I\right) \varphi(z ; 0, I) dz \\
\end{aligned}
$$

From the two results above, we can iteratively update $\theta$ and $\sigma^{2}$ via gradient descent. The integrals can be approximated via numerical integration.


% iterative gradient descent
